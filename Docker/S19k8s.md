
# k8s

integrated platforms: 1- containerd.io (low level) 2- CRI-O (high level) 3- CRI-dockerd(mirantis) (mid level) [docker (highlevel)]


### mirantis

is cloud tools - its a tools of openstack - 

before version 1.24 k8s mid level connection between k8s and docker was dockershim.

k8s (v1.23) ---> dockershim -----> docker

but in version 1.24 , k8s to upgrade older version to it introduced cri-o dockerd (by mirantis co.) to keep connection with docker in servers

k8s (v1.24) ---> cri-o dockerd (by mirantis co.) -----> docker


https://kubernetes.io/docs/setup/production-environment/container-runtimes


Note: These instructions assume that you are using the cri-dockerd adapter to integrate Docker Engine with Kubernetes.

k8s prioroty for container runtime:

1- containerd  --- is recommanded
2- CRI-O
3- Docker Engine
4- Mirantis Container Runtime

for use docker engin follow instruction:

Docker Engine
Note: These instructions assume that you are using the cri-dockerd adapter to integrate Docker Engine with Kubernetes.
On each of your nodes, install Docker for your Linux distribution as per Install Docker Engine.

Install cri-dockerd, following the instructions in that source code repository.

For cri-dockerd, the CRI socket is /run/cri-dockerd.sock by default.

Mirantis Container Runtime 
Mirantis Container Runtime (MCR) is a commercially available container runtime that was formerly known as Docker Enterprise Edition.

You can use Mirantis Container Runtime with Kubernetes using the open source cri-dockerd component, included with MCR.

To learn more about how to install Mirantis Container Runtime, visit MCR Deployment Guide.

Check the systemd unit named cri-docker.socket to find out the path to the CRI socket.




### etcd or cluster store:

its stand for /etc distributed. its a store to keep config files. acces only by api server. its a key-value based meta data storage to manage critical infor mation about cluster. its highly recommand to have backup plan for etcd in cluster .

cause if master node in k8s crash or has benn down , all cluster would be lost. if you have backup from etcd just run another k8s and restore etcd in it and all you have restore in it. 


interview qustion: k8s backup tools: 1- k10 (90% market - kasten.io its buy by veeam backup) 2- velero (10% market)  3- ...... other is not important


practice: try to install and use kasten. its free up to 5 node ( cluster).



#### K8s have customise versions:  

in private env. --> openshift (by rehl and need license - OKD -can install in private cloud ) - suse rancher (by suse - can install in private cloud.) 


in public env. --> eks - aks - gke - ibm-kube - oracle - ..


its important you learn use k8s in general. 


#### kube - scheduler 

assign work to nodes - decide where to start work loads , on which node. choosing node. multiple criteria is needed and can be set to sceduler. 
individual & collective resource requirements, hardware/software/policy constraints, affinity & anti-affinity specifications, data locality & inter-workload interference.


affinity & anti affinity:

some app needs to be up beside together. side care container. for ex.: redis and backends pod. if backed shuts in any node and up in other node k8s automatically down redis and up it in beside backends pod. this is affinity and k8s has feature to set this attr.

In the same way, it is anti-affinity. 

#### kube-controller-manager

watch for changes. kubelet is report currentstat/desiredstat to kube-controller to calculate(sum) it by kube-controller. 
 controller is sprated process (all module) that have child proc( with one pid) all compiled into a single binary and run in a single process.

***It includes***: 

**Node**(all nodes is up and runs with hello message with time schedule )/**Replication**(sum of currentstat/desiredstat 's is correct)/**Endpoints**(network interfaces of pode - ep - with ping it)/**Service-Account**(account managment- AAA - acoount an tokens ,... )/**Token Controller**(to join workers) 

arcitecture is very important for t-shoot. 


### main command

is kubectl - some version have alias of it.

write alias when you install k8s----> for ex.: kubectl==k


in bash:

alias   - show all aliases

for ex.:

alias cd..="cd .."  - after this command you can use cd.. (with no space) in command env.

to delete that alias:

unalias cd..


all node in k8s have kubelet and kubeproxy  to negotiate each other. all feature is cantainer (system pods) base except kubelet and kubectl and kubeadm. they are daemon. 

we should install kubelet and kubeproxy and container runtime in all node in k8s. 

maser node have rule 2n+1. 

#### kube let

Compare running containers with Received PodSpecs(desired stat). 

#### kube proxy

It is a proxy service that runs on each node & helps in making services available to the external host. It helps to forwarding requests to assigned networks.
Responsible for configuring network rules for each nodes.
Assigning One Single IP to all containers in a pod.



Manifest File is a specification of a Kubernetes API object in JSON/YAML format.
A manifest specifies “Desired State” of an object.
Kubeconfig can be one or more Manifest Files which they will send to API Server.

#### cloud-controller-manager

talks to cloud provider. for ex.: amazon or private cloud ,... .k8s can make vm in aws with this feature. no need to make it manually in aws.



### pod

smallest & most basic deployable objects in Kubernetes.
Pods contain one or more containers, Containers contain one or more services.

Pods can be deployed on a cluster with Manifest (yml) Files.
Manifest files will be sent to API Server and then can be executed on one of nodes.

1 pod == 1main container

for ex. 1 nginx pod may include: 1 nginx (main container) with 1 nginx log scrapper (side care container)

in voting app we have 5 pod. its recommand and best practice.

#### horizontal scaling : 

means when we have increase replica number of nginx from 1 to 5 we increase number of pod that include 1 nginx. (not 1 pod include 5 nginx.vertical is wrong)

horizontal auto scaling that called HPA. we should detemine min and max interval. k8s auto scale it. just determine treshold for ex. cpu. 3~10 cpu treshold 20%~80~.


#### pods life cycle


pending ---> running --------> succeeded (exit0) ----> end
             unknown      |_____> failed (exit non zero)


They’ll go from Pending Phase to Running Phase with starting one of Containers.
Then, related to state of containers, they’ll ended with Succeeded or Failed states.

             
when controller manager not get report of pods then change its status for speciifific period of time ( 5 time retry) unknownmany be some minute. then try to run it on other pod. 
 every pod hane endpoint or ep with one ip and port. port pod = port container

 
## Cgroups

Linux control groups, or cgroups, is a kernel feature that allows an administrator to allocate resources such as CPU, memory, and I/O bandwidth to groups of processes.

k8s manage pods resource and isolation with linux cgroup. k8s (same as linux lpic3) make namespace with cgroup and put pods inside it.  for ex.: group category: monitoring - staging - prod

### name space or NS

k8s has 4 default name space:

1- defalut namespace is for object with no other namespace , its recommand to change it.

2- kube-system: is for api server , kubescheduler ,... its for k8s obect system

3- kube-public - is ns for clould provider

4- kube-node-lease: is for sending heart bit in system. 


#### kuber installation

kubectl --> command is for manage app .

kubeadm --> command is for manage infra for node managmnet . its k8s kuber provisioner. kubeadm is main and used in every where in datacenters ,....

but other k8s provisioner is minikube , k3s , kind , ..... is lightweight of k8s.single node cluster. 

minikube is single node (cluster) its master and worker. its for labs and laptop.


install minikube:


https://phoenixnap.com/kb/install-minikube-on-ubuntu


sudo apt-get install curl



sudo apt-get install apt-transport-https



sudo apt install virtualbox virtualbox-ext-pack






wget https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64

sudo cp minikube-linux-amd64 /usr/local/bin/minikube


sudo chmod 755 /usr/local/bin/minikube


minikube version




install kubectl:


curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x ./kubectl

sudo mv ./kubectl /usr/local/bin/kubectl

kubectl version -o json

minikube start --kubernetes-version='1.23' --driver=none

apt install conntrack


kubectl config view




sudo minikube start --kubernetes-version='1.23' --driver=none

dirive none needs permission sudo


we use v1.23 to see connectivity with docker.








we can install minikube and run it on:

1- ubuntu  : --driver=none

2- docker  : --driver=docker

3- virtual box : --driver=vm

we should specify above option --driver option command

k8s ----container rumtime(docker)---->pod -----container rumtime(docker)---->container

then for every runnong container we see 2 container name (container- contanier pod) in docker ps. 

app --> pod -->kubelet -->controller 



minikube status

with minikube and kubeadm --> we initialize clustering in infra. after that we can use kubectl command to manage apps layers.




## k8s dashboards:

kubernetese dashboard has gui web based dashboard . lenz is dashboard for k8s too. you can create pod within dahboard.

just to add node and k8s services use minikube.


minikube dashboard   - run gui dashboard


run btop to see cpu usage.

btop






















